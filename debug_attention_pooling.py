#!/usr/bin/env python3
"""
è°ƒè¯•æ³¨æ„åŠ›æ± åŒ–æ¨¡å‹
"""

import yaml
import torch
from data_utils import load_raw_data, preprocess_features, create_sliding_windows
from transformer_improved import ImprovedTransformer

def main():
    print("ğŸ” è°ƒè¯•æ³¨æ„åŠ›æ± åŒ–æ¨¡å‹")
    print("=" * 50)
    
    # 1. åŠ è½½é…ç½®
    with open('Transformer_attention_pooling.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: Transformer_attention_pooling.yaml")
    print(f"ğŸ¤– æ¨¡å‹ç±»å‹: {config['model']}")
    
    # 2. æ£€æŸ¥æ¨¡å‹ç±»å‹è¯†åˆ«
    is_dl = config["model"] in ["Transformer", "ImprovedTransformer", "HybridTransformer", "LSTM", "GRU", "TCN"]
    print(f"ğŸ” æ˜¯å¦ä¸ºDLæ¨¡å‹: {is_dl}")
    
    # 3. åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    df = load_raw_data('Project1140.csv')
    df_proj = df[df['ProjectID'] == 1140.0]
    
    # 4. é¢„å¤„ç†
    print("ğŸ”§ é¢„å¤„ç†æ•°æ®...")
    df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = \
        preprocess_features(df_proj, config)
    
    print(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(df_clean)} è¡Œ")
    print(f"ğŸ“ˆ å†å²ç‰¹å¾: {hist_feats}")
    print(f"ğŸ“ˆ é¢„æµ‹ç‰¹å¾: {fcst_feats}")
    
    # 5. åˆ›å»ºæ»‘åŠ¨çª—å£
    print("\nğŸªŸ åˆ›å»ºæ»‘åŠ¨çª—å£...")
    X_hist, X_fcst, y, hours, dates = create_sliding_windows(
        df_clean,
        past_hours=config['past_hours'],
        future_hours=config['future_hours'],
        hist_feats=hist_feats,
        fcst_feats=fcst_feats,
        no_hist_power=not config.get('use_pv', True)
    )
    
    print(f"âœ… æ»‘åŠ¨çª—å£åˆ›å»ºæˆåŠŸ:")
    print(f"   å†å²æ•°æ®å½¢çŠ¶: {X_hist.shape}")
    print(f"   é¢„æµ‹æ•°æ®å½¢çŠ¶: {X_fcst.shape}")
    print(f"   ç›®æ ‡æ•°æ®å½¢çŠ¶: {y.shape}")
    
    # 6. æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("\nğŸ¤– æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    try:
        # è·å–æ¨¡å‹å‚æ•°
        complexity = config.get('model_complexity', 'low')
        if complexity in config['model_params']:
            mp = config['model_params'][complexity].copy()
        else:
            mp = config.get('model_params', {}).copy()
        
        mp['use_forecast'] = config.get('use_forecast', False)
        mp['past_hours'] = config['past_hours']
        mp['future_hours'] = config['future_hours']
        
        print(f"ğŸ” æ¨¡å‹å‚æ•°: {mp}")
        
        model = ImprovedTransformer(
            hist_dim=len(hist_feats),
            fcst_dim=len(fcst_feats),
            config=mp
        )
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        
        # 7. æµ‹è¯•å‰å‘ä¼ æ’­
        print("\nğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            # ä½¿ç”¨å°æ‰¹é‡æµ‹è¯•
            batch_size = min(4, X_hist.shape[0])
            hist_batch = torch.tensor(X_hist[:batch_size], dtype=torch.float32)
            fcst_batch = torch.tensor(X_fcst[:batch_size], dtype=torch.float32)
            
            output = model(hist_batch, fcst_batch)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   è¾“å…¥å½¢çŠ¶: hist={hist_batch.shape}, fcst={fcst_batch.shape}")
            print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"   è¾“å‡ºèŒƒå›´: {output.min().item():.3f} - {output.max().item():.3f}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nğŸ‰ è°ƒè¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
