#!/usr/bin/env python3
"""
ç®€å•è®­ç»ƒæµ‹è¯•
"""

import yaml
import torch
from data_utils import load_raw_data, preprocess_features, create_sliding_windows
from transformer import Transformer

def main():
    print("ğŸ” ç®€å•è®­ç»ƒæµ‹è¯•")
    print("=" * 50)
    
    # 1. åŠ è½½é…ç½®
    with open('Transformer_low_PV_plus_NWP_24h_noTE.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: Transformer_low_PV_plus_NWP_24h_noTE.yaml")
    
    # 2. åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    df = load_raw_data('Project1140.csv')
    df_proj = df[df['ProjectID'] == 1140.0]
    
    # 3. é¢„å¤„ç†
    print("ğŸ”§ é¢„å¤„ç†æ•°æ®...")
    df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = \
        preprocess_features(df_proj, config)
    
    print(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(df_clean)} è¡Œ")
    
    # 4. åˆ›å»ºæ»‘åŠ¨çª—å£
    print("\nğŸªŸ åˆ›å»ºæ»‘åŠ¨çª—å£...")
    X_hist, X_fcst, y, hours, dates = create_sliding_windows(
        df_clean,
        past_hours=config['past_hours'],
        future_hours=config['future_hours'],
        hist_feats=hist_feats,
        fcst_feats=fcst_feats,
        no_hist_power=not config.get('use_pv', True)
    )
    
    print(f"âœ… æ»‘åŠ¨çª—å£åˆ›å»ºæˆåŠŸ:")
    print(f"   å†å²æ•°æ®å½¢çŠ¶: {X_hist.shape}")
    print(f"   é¢„æµ‹æ•°æ®å½¢çŠ¶: {X_fcst.shape}")
    print(f"   ç›®æ ‡æ•°æ®å½¢çŠ¶: {y.shape}")
    
    # 5. åˆ›å»ºæ¨¡å‹
    print("\nğŸ¤– åˆ›å»ºæ¨¡å‹...")
    try:
        # è·å–æ¨¡å‹å‚æ•°
        complexity = config.get('model_complexity', 'low')
        if complexity in config['model_params']:
            mp = config['model_params'][complexity].copy()
        else:
            mp = config.get('model_params', {}).copy()
        
        mp['use_forecast'] = config.get('use_forecast', False)
        mp['past_hours'] = config['past_hours']
        mp['future_hours'] = config['future_hours']
        
        # åˆ›å»ºæ¨¡å‹
        model = Transformer(
            hist_dim=len(hist_feats),
            fcst_dim=len(fcst_feats),
            config=mp
        )
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        
        # 6. æµ‹è¯•è®­ç»ƒå¾ªç¯
        print("\nğŸ¯ æµ‹è¯•è®­ç»ƒå¾ªç¯...")
        try:
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
            criterion = torch.nn.MSELoss()
            
            # ä½¿ç”¨å°æ‰¹é‡æµ‹è¯•
            batch_size = 4
            hist_batch = torch.tensor(X_hist[:batch_size], dtype=torch.float32)
            fcst_batch = torch.tensor(X_fcst[:batch_size], dtype=torch.float32)
            y_batch = torch.tensor(y[:batch_size], dtype=torch.float32)
            
            print(f"   è¾“å…¥å½¢çŠ¶: hist={hist_batch.shape}, fcst={fcst_batch.shape}")
            print(f"   ç›®æ ‡å½¢çŠ¶: {y_batch.shape}")
            
            # å‰å‘ä¼ æ’­
            model.train()
            optimizer.zero_grad()
            
            output = model(hist_batch, fcst_batch)
            print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"   è¾“å‡ºè®¾å¤‡: {output.device}")
            
            # è®¡ç®—æŸå¤±
            loss = criterion(output, y_batch)
            print(f"   æŸå¤±å€¼: {loss.item():.4f}")
            
            # åå‘ä¼ æ’­
            loss.backward()
            print(f"   åå‘ä¼ æ’­æˆåŠŸ")
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            print(f"   å‚æ•°æ›´æ–°æˆåŠŸ")
            
            print(f"âœ… è®­ç»ƒå¾ªç¯æµ‹è¯•æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¾ªç¯æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nğŸ‰ ç®€å•è®­ç»ƒæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
