#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•è„šæœ¬ - æœ€å°åŒ–è¿è¡Œ
"""

import yaml
import torch
import numpy as np
from data_utils import load_raw_data, preprocess_features, create_sliding_windows, split_data
from transformer import Transformer
from train_utils import get_optimizer, get_scheduler

def main():
    print("ğŸ§ª ç®€å•æµ‹è¯•å¼€å§‹...")
    
    try:
        # 1. åŠ è½½é…ç½®
        with open('Transformer_low_PV_plus_NWP_24h_noTE.yaml', 'r') as f:
            config = yaml.safe_load(f)
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # 2. åŠ è½½æ•°æ®
        df = load_raw_data('Project1140.csv')
        df_proj = df[df['ProjectID'] == 1140.0]
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df_proj)} è¡Œ")
        
        # 3. é¢„å¤„ç†
        df_clean, hist_feats, fcst_feats, scaler_hist, scaler_fcst, scaler_target = \
            preprocess_features(df_proj, config)
        print(f"âœ… é¢„å¤„ç†æˆåŠŸ: {len(df_clean)} è¡Œ")
        
        # 4. åˆ›å»ºæ»‘åŠ¨çª—å£
        X_hist, X_fcst, y, hours, dates = create_sliding_windows(
            df_clean,
            past_hours=config['past_hours'],
            future_hours=config['future_hours'],
            hist_feats=hist_feats,
            fcst_feats=fcst_feats,
            no_hist_power=not config.get('use_pv', True)
        )
        print(f"âœ… æ»‘åŠ¨çª—å£åˆ›å»ºæˆåŠŸ: {X_hist.shape}")
        
        # 5. æ•°æ®åˆ†å‰²
        Xh_tr, Xf_tr, y_tr, hrs_tr, dates_tr, \
        Xh_va, Xf_va, y_va, hrs_va, dates_va, \
        Xh_te, Xf_te, y_te, hrs_te, dates_te = split_data(
            X_hist, X_fcst, y, hours, dates,
            train_ratio=0.8,
            val_ratio=0.1
        )
        print(f"âœ… æ•°æ®åˆ†å‰²æˆåŠŸ: è®­ç»ƒé›† {Xh_tr.shape[0]} æ ·æœ¬")
        
        # 6. åˆ›å»ºæ¨¡å‹
        mp = config['model_params']['low']
        mp['use_forecast'] = config.get('use_forecast', False)
        mp['past_hours'] = config['past_hours']
        mp['future_hours'] = config['future_hours']
        
        model = Transformer(Xh_tr.shape[2], Xf_tr.shape[2], mp)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {sum(p.numel() for p in model.parameters())} å‚æ•°")
        
        # 7. æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            test_input_hist = torch.randn(2, Xh_tr.shape[1], Xh_tr.shape[2])
            test_input_fcst = torch.randn(2, Xf_tr.shape[1], Xf_tr.shape[2])
            output = model(test_input_hist, test_input_fcst)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ: {output.shape}")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
