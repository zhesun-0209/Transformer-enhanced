"""
eval/eval_utils.py

Utilities to save summary, predictions, training logs, and call plotting routines.
"""

import os
import pandas as pd
import numpy as np
# ç»˜å›¾åŠŸèƒ½å·²ç§»é™¤ï¼Œé»˜è®¤ä¸ä¿å­˜å›¾ç‰‡
from excel_utils import save_plant_excel_results
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ===== Define Deep Learning model names =====
DL_MODELS = {"Transformer", "LSTM", "GRU", "TCN"}

def save_results(
    model,
    metrics: dict,
    dates: list,
    y_true: np.ndarray,
    Xh_test: np.ndarray,
    Xf_test: np.ndarray,
    config: dict
):
    """
    Save summary.csv, predictions.csv, training_log.csv, and generate plots
    under config['save_dir'].

    Args:
        model:   Trained DL or sklearn model
        metrics: Dictionary containing:
                 'test_loss', 'train_time_sec', 'param_count', 'rmse', 'mae',
                 'predictions' (n,h), 'y_true' (n,h),
                 'dates' (n), 'epoch_logs' (list of dicts)
        dates:   List of datetime strings
        y_true, Xh_test, Xf_test: Used for legacy or optional plots
        config:  Dictionary with keys like 'save_dir', 'model', 'plot_days', 'scaler_target'
    """
    # ä½¿ç”¨é…ç½®ä¸­çš„ä¿å­˜ç›®å½•
    save_dir = config.get('save_dir', './results')
    os.makedirs(save_dir, exist_ok=True)

    # Extract predictions and ground truth
    preds = metrics['predictions']
    yts   = metrics['y_true']

    # ===== Capacity Factorä¸éœ€è¦é€†æ ‡å‡†åŒ–ï¼ˆå·²ç»æ˜¯0-100èŒƒå›´ï¼‰ =====
    # æ•°æ®å·²ç»æ˜¯åŸå§‹å°ºåº¦ï¼Œç›´æ¥ä½¿ç”¨

    # ===== è®¡ç®—æŸå¤±æŒ‡æ ‡ =====
    # æ‰€æœ‰è®¡ç®—æ–¹å¼åœ¨æ•°å­¦ä¸Šç­‰ä»·ï¼Œç›´æ¥è®¡ç®—ä¸€æ¬¡å³å¯
    test_mse = np.mean((preds - yts) ** 2)
    test_rmse = np.sqrt(test_mse)
    test_mae = np.mean(np.abs(preds - yts))
    
    # è®¡ç®—RÂ² (å†³å®šç³»æ•°)
    y_mean = np.mean(yts)
    ss_tot = np.sum((yts - y_mean) ** 2)  # æ€»å¹³æ–¹å’Œ
    ss_res = np.sum((yts - preds) ** 2)   # æ®‹å·®å¹³æ–¹å’Œ
    r_square = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
    
    # åªè®¡ç®—åŸå§‹å°ºåº¦æŒ‡æ ‡

    # è·å–ä¿å­˜é€‰é¡¹
    save_options = config.get('save_options', {})
    print(f"ğŸ” è°ƒè¯•: save_options = {save_options}")
    print(f"ğŸ” è°ƒè¯•: save_excel_results = {save_options.get('save_excel_results', True)}")
    
    # ===== 1. summary.csv å·²å®Œå…¨ç¦ç”¨ =====
    # ä¸å†ä¿å­˜summary.csvæ–‡ä»¶ï¼Œåªä¿å­˜Excelæ–‡ä»¶
    # å®šä¹‰summaryå˜é‡ä¾›Excelä¿å­˜ä½¿ç”¨
    summary = {
        'model':           config['model'],
        'use_hist_weather': config.get('use_hist_weather', False),
        'use_forecast':    config.get('use_forecast', False),
        'past_days':       config.get('past_days', 1),
        'model_complexity': config.get('model_complexity', 'low'),
        'correlation_level': config.get('correlation_level', 'high'),
        'use_time_encoding': config.get('use_time_encoding', True),
        'past_hours':      config['past_hours'],
        'future_hours':    config['future_hours'],
        
        # ä¸»è¦æŒ‡æ ‡
        'mse':             test_mse,   # æ•´ä¸ªæµ‹è¯•é›†MSE (Capacity FactorÂ²)
        'rmse':            test_rmse,  # æ•´ä¸ªæµ‹è¯•é›†RMSE (Capacity Factor)
        'mae':             test_mae,   # æ•´ä¸ªæµ‹è¯•é›†MAE (Capacity Factor)
        'r_square':        r_square,   # RÂ²å†³å®šç³»æ•°
        
        # æ€§èƒ½æŒ‡æ ‡
        'train_time_sec':  metrics.get('train_time_sec'),
        'inference_time_sec': metrics.get('inference_time_sec', np.nan),
        'param_count':     metrics.get('param_count'),
        'samples_count':   len(preds),  # æµ‹è¯•æ ·æœ¬æ•°é‡
    }
    # ä¸ä¿å­˜summary.csvï¼Œåªä¿å­˜Excelæ–‡ä»¶

    # ===== 2. Save predictions.csv =====
    if save_options.get('save_predictions', True):
        hrs = metrics.get('hours')
        dates_list = metrics.get('dates', dates)
        records = []
        n_samples, horizon = preds.shape
        
        # Handle case where hours information is not available
        if hrs is None:
            # Generate default hour sequence if not provided
            hrs = np.tile(np.arange(horizon), (n_samples, 1))
        
        for i in range(n_samples):
            start = pd.to_datetime(dates_list[i]) - pd.Timedelta(hours=horizon - 1)
            for h in range(horizon):
                dt = start + pd.Timedelta(hours=h)
                records.append({
                    'window_index':      i,
                    'forecast_datetime': dt,
                    'hour':              int(hrs[i, h]) if hrs is not None else dt.hour,
                    'y_true':            float(yts[i, h]),
                    'y_pred':            float(preds[i, h])
                })
        pd.DataFrame(records).to_csv(os.path.join(save_dir, "predictions.csv"), index=False)

    # ===== 3. Save training log (only if DL) =====
    is_dl = config['model'] in DL_MODELS
    if is_dl and 'epoch_logs' in metrics and save_options.get('save_training_log', True):
        pd.DataFrame(metrics['epoch_logs']).to_csv(
            os.path.join(save_dir, "training_log.csv"), index=False
        )

    # ===== 4. Save plots =====
    days = config.get('plot_days', None)
    
    # ç»˜å›¾åŠŸèƒ½å·²ç§»é™¤ï¼Œé»˜è®¤ä¸ä¿å­˜å›¾ç‰‡
    # å¦‚éœ€ä¿å­˜å›¾ç‰‡ï¼Œè¯·è®¾ç½®ç›¸åº”çš„save_optionsä¸ºTrue
    
    # ä¿å­˜Excelç»“æœæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    print(f"ğŸ” è°ƒè¯•: å‡†å¤‡ä¿å­˜Excelç»“æœï¼Œæ¡ä»¶åˆ¤æ–­: {save_options.get('save_excel_results', True)}")
    if save_options.get('save_excel_results', True):
        print(f"ğŸ” è°ƒè¯•: è¿›å…¥Excelä¿å­˜é€»è¾‘")
        # æ„å»ºå®éªŒç»“æœæ•°æ®
        result_data = {
            'config': {
                'model': config['model'],
                'use_pv': config.get('use_pv', True),
                'use_hist_weather': config.get('use_hist_weather', False),
                'use_forecast': config.get('use_forecast', False),
                'weather_category': config.get('weather_category', 'irradiance'),
                'use_time_encoding': config.get('use_time_encoding', True),
                'past_days': config.get('past_days', 1),
                'model_complexity': config.get('model_complexity', 'low'),
                'epochs': config.get('epochs', 15),
                'batch_size': config.get('batch_size', 32),
                'learning_rate': config.get('learning_rate', 0.001)
            },
            'metrics': {
                'train_time_sec': summary['train_time_sec'],
                'inference_time_sec': summary['inference_time_sec'],
                'param_count': summary['param_count'],
                'samples_count': summary['samples_count'],
                'mse': summary['mse'],
                'rmse': summary['rmse'],
                'mae': summary['mae'],
                'nrmse': metrics.get('nrmse', np.nan),
                'r_square': summary['r_square'],
                'smape': metrics.get('smape', np.nan),
                'best_epoch': metrics.get('best_epoch', np.nan),
                'final_lr': metrics.get('final_lr', np.nan),
                'gpu_memory_used': metrics.get('gpu_memory_used', 0)
            }
        }
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        from excel_utils import append_plant_excel_results
        print(f"ğŸ” è°ƒè¯•: plant_id={config.get('plant_id', 'unknown')}, save_dir={save_dir}")
        csv_file = append_plant_excel_results(
            plant_id=config.get('plant_id', 'unknown'),
            result=result_data,
            save_dir=save_dir
        )
        print(f"ğŸ” è°ƒè¯•: CSVæ–‡ä»¶å·²ä¿å­˜åˆ° {csv_file}")
    else:
        print(f"ğŸ” è°ƒè¯•: è·³è¿‡Excelä¿å­˜ï¼Œsave_excel_results = False")

    print(f"[INFO] Results saved in {save_dir}")

def save_season_hour_results(
    model,
    metrics: dict,
    dates: list,
    y_true: np.ndarray,
    Xh_test: np.ndarray,
    Xf_test: np.ndarray,
    config: dict
):
    """
    ä¿å­˜season and hour analysisç»“æœ
    ä¸ºæ¯ä¸ªå‚ä¿å­˜prediction.csvå’Œsummary.csvåˆ°æŒ‡å®šçš„Driveè·¯å¾„
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        metrics: åŒ…å«é¢„æµ‹ç»“æœå’ŒæŒ‡æ ‡çš„å­—å…¸
        dates: æ—¥æœŸåˆ—è¡¨
        y_true: çœŸå®å€¼
        Xh_test, Xf_test: æµ‹è¯•æ•°æ®
        config: é…ç½®å­—å…¸
    """
    # è®¾ç½®Driveè·¯å¾„
    drive_path = "/content/drive/MyDrive/Solar PV electricity/hour and season analysis"
    os.makedirs(drive_path, exist_ok=True)
    
    # æå–é¢„æµ‹ç»“æœå’ŒçœŸå®å€¼
    preds = metrics['predictions']
    yts = metrics['y_true']
    
    # è®¡ç®—æŒ‡æ ‡
    test_mse = np.mean((preds - yts) ** 2)
    test_rmse = np.sqrt(test_mse)
    test_mae = np.mean(np.abs(preds - yts))
    
    # è®¡ç®—RÂ²
    y_mean = np.mean(yts)
    ss_tot = np.sum((yts - y_mean) ** 2)
    ss_res = np.sum((yts - preds) ** 2)
    r_square = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
    
    # è®¡ç®—NRMSEå’ŒSMAPE
    nrmse = (test_rmse / (test_mae + 1e-8)) * 100 if test_mae > 0 else 0
    smape = (2 * test_mae / (test_mae + 1e-8)) * 100 if test_mae > 0 else 0
    
    # è·å–é¡¹ç›®ID
    project_id = config.get('plant_id', 'unknown')
    model_name = config.get('model', 'unknown')
    
    # 1. ä¿å­˜prediction.csv
    prediction_file = os.path.join(drive_path, f"{project_id}_prediction.csv")
    
    # å‡†å¤‡é¢„æµ‹ç»“æœæ•°æ®
    hrs = metrics.get('hours')
    dates_list = metrics.get('dates', dates)
    records = []
    n_samples, horizon = preds.shape
    
    # å¤„ç†å°æ—¶ä¿¡æ¯
    if hrs is None:
        hrs = np.tile(np.arange(horizon), (n_samples, 1))
    
    for i in range(n_samples):
        start = pd.to_datetime(dates_list[i]) - pd.Timedelta(hours=horizon - 1)
        for h in range(horizon):
            dt = start + pd.Timedelta(hours=h)
            records.append({
                'date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                'ground_truth': float(yts[i, h]),
                'prediction': float(preds[i, h]),
                'model': model_name,
                'project_id': project_id,
                'window_index': i,
                'hour': int(hrs[i, h]) if hrs is not None else dt.hour
            })
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    pred_df = pd.DataFrame(records)
    if os.path.exists(prediction_file):
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
        existing_df = pd.read_csv(prediction_file)
        pred_df = pd.concat([existing_df, pred_df], ignore_index=True)
    pred_df.to_csv(prediction_file, index=False)
    print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜: {prediction_file}")
    
    # 2. ä¿å­˜summary.csv
    summary_file = os.path.join(drive_path, f"{project_id}_summary.csv")
    
    # å‡†å¤‡summaryæ•°æ®
    summary_data = {
        'model': model_name,
        'weather_level': config.get('weather_category', 'unknown'),
        'lookback_hours': config.get('past_hours', 24),
        'complexity_level': config.get('model_complexity', 'unknown').replace('level', ''),
        'dataset_scale': '80%',
        'use_pv': config.get('use_pv', False),
        'use_hist_weather': config.get('use_hist_weather', False),
        'use_forecast': config.get('use_forecast', False),
        'use_time_encoding': config.get('use_time_encoding', False),
        'past_days': config.get('past_days', 1),
        'use_ideal_nwp': config.get('use_ideal_nwp', False),
        'selected_weather_features': str(config.get('selected_weather_features', [])),
        'epochs': config.get('epochs', 0),
        'batch_size': config.get('train_params', {}).get('batch_size', 0),
        'learning_rate': config.get('train_params', {}).get('learning_rate', 0.0),
        'train_time_sec': round(metrics.get('train_time_sec', 0), 4),
        'inference_time_sec': round(metrics.get('inference_time_sec', 0), 4),
        'param_count': metrics.get('param_count', 0),
        'samples_count': len(preds),
        'best_epoch': metrics.get('best_epoch', 0),
        'final_lr': metrics.get('final_lr', 0.0),
        'mse': round(test_mse, 4),
        'rmse': round(test_rmse, 4),
        'mae': round(test_mae, 4),
        'nrmse': round(nrmse, 4),
        'r_square': round(r_square, 4),
        'smape': round(smape, 4),
        'gpu_memory_used': metrics.get('gpu_memory_used', 0),
        'config_file': f"season_hour_{model_name.lower()}.yaml"
    }
    
    # ä¿å­˜summaryç»“æœ
    summary_df = pd.DataFrame([summary_data])
    if os.path.exists(summary_file):
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
        existing_df = pd.read_csv(summary_file)
        summary_df = pd.concat([existing_df, summary_df], ignore_index=True)
    summary_df.to_csv(summary_file, index=False)
    print(f"ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: {summary_file}")
    
    print(f"âœ… Season and Hour Analysisç»“æœå·²ä¿å­˜åˆ°: {drive_path}")
    
    return summary_data
