#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯æ”¹è¿›çš„Transformeræ¶æ„
"""

import torch
import yaml
from transformer_improved import ImprovedTransformer, HybridTransformer
from transformer import Transformer

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    # æµ‹è¯•é…ç½®
    config = {
        'd_model': 64,
        'num_heads': 4,
        'num_layers': 2,
        'hidden_dim': 32,
        'dropout': 0.1,
        'future_hours': 24,
        'use_forecast': True,
        'pooling_type': 'attention'
    }
    
    hist_dim = 10
    fcst_dim = 5
    
    try:
        # æµ‹è¯•åŸå§‹Transformer
        original_model = Transformer(hist_dim, fcst_dim, config)
        print("âœ… åŸå§‹Transformeråˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ”¹è¿›Transformer
        improved_model = ImprovedTransformer(hist_dim, fcst_dim, config)
        print("âœ… æ”¹è¿›Transformeråˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ··åˆTransformer
        hybrid_model = HybridTransformer(hist_dim, fcst_dim, config)
        print("âœ… æ··åˆTransformeråˆ›å»ºæˆåŠŸ")
        
        return original_model, improved_model, hybrid_model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return None, None, None

def test_forward_pass(original_model, improved_model, hybrid_model):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\nğŸ§ª æµ‹è¯•å‰å‘ä¼ æ’­...")
    
    batch_size = 2
    past_hours = 24
    future_hours = 24
    hist_dim = 10
    fcst_dim = 5
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    hist_data = torch.randn(batch_size, past_hours, hist_dim)
    fcst_data = torch.randn(batch_size, future_hours, fcst_dim)
    
    try:
        # æµ‹è¯•åŸå§‹æ¨¡å‹
        with torch.no_grad():
            original_output = original_model(hist_data, fcst_data)
            print(f"âœ… åŸå§‹Transformerè¾“å‡ºå½¢çŠ¶: {original_output.shape}")
            
            # æµ‹è¯•æ”¹è¿›æ¨¡å‹
            improved_output = improved_model(hist_data, fcst_data)
            print(f"âœ… æ”¹è¿›Transformerè¾“å‡ºå½¢çŠ¶: {improved_output.shape}")
            
            # æµ‹è¯•æ··åˆæ¨¡å‹
            hybrid_output = hybrid_model(hist_data, fcst_data)
            print(f"âœ… æ··åˆTransformerè¾“å‡ºå½¢çŠ¶: {hybrid_output.shape}")
            
            # éªŒè¯è¾“å‡ºèŒƒå›´
            print(f"ğŸ“Š è¾“å‡ºèŒƒå›´æ£€æŸ¥:")
            print(f"   åŸå§‹æ¨¡å‹: [{original_output.min():.3f}, {original_output.max():.3f}]")
            print(f"   æ”¹è¿›æ¨¡å‹: [{improved_output.min():.3f}, {improved_output.max():.3f}]")
            print(f"   æ··åˆæ¨¡å‹: [{hybrid_output.min():.3f}, {hybrid_output.max():.3f}]")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, future_hours)
            assert original_output.shape == expected_shape, f"åŸå§‹æ¨¡å‹è¾“å‡ºå½¢çŠ¶é”™è¯¯: {original_output.shape}"
            assert improved_output.shape == expected_shape, f"æ”¹è¿›æ¨¡å‹è¾“å‡ºå½¢çŠ¶é”™è¯¯: {improved_output.shape}"
            assert hybrid_output.shape == expected_shape, f"æ··åˆæ¨¡å‹è¾“å‡ºå½¢çŠ¶é”™è¯¯: {hybrid_output.shape}"
            
            print("âœ… æ‰€æœ‰æ¨¡å‹è¾“å‡ºå½¢çŠ¶æ­£ç¡®")
            
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")

def test_different_pooling_types():
    """æµ‹è¯•ä¸åŒçš„æ± åŒ–ç±»å‹"""
    print("\nğŸ§ª æµ‹è¯•ä¸åŒæ± åŒ–ç±»å‹...")
    
    config_base = {
        'd_model': 32,
        'num_heads': 2,
        'num_layers': 1,
        'hidden_dim': 16,
        'dropout': 0.1,
        'future_hours': 12,
        'use_forecast': False
    }
    
    pooling_types = ['last', 'mean', 'max', 'attention', 'learned_attention']
    
    for pooling_type in pooling_types:
        try:
            config = config_base.copy()
            config['pooling_type'] = pooling_type
            
            model = ImprovedTransformer(5, 0, config)
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            test_input = torch.randn(1, 12, 5)
            with torch.no_grad():
                output = model(test_input)
                
            print(f"âœ… {pooling_type} æ± åŒ–ç±»å‹æµ‹è¯•æˆåŠŸ, è¾“å‡ºå½¢çŠ¶: {output.shape}")
            
        except Exception as e:
            print(f"âŒ {pooling_type} æ± åŒ–ç±»å‹æµ‹è¯•å¤±è´¥: {e}")

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½...")
    
    config_files = [
        'Transformer_low_PV_plus_NWP_24h_noTE.yaml',
        'Transformer_improved_PV_plus_NWP_24h.yaml',
        'Transformer_attention_pooling.yaml',
        'Transformer_hybrid.yaml'
    ]
    
    for config_file in config_files:
        try:
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            
            print(f"âœ… {config_file} åŠ è½½æˆåŠŸ")
            print(f"   æ¨¡å‹: {config.get('model', 'N/A')}")
            print(f"   å¤æ‚åº¦: {config.get('model_complexity', 'N/A')}")
            
            if 'model_params' in config and 'low' in config['model_params']:
                pooling_type = config['model_params']['low'].get('pooling_type', 'N/A')
                print(f"   æ± åŒ–ç±»å‹: {pooling_type}")
                
        except Exception as e:
            print(f"âŒ {config_file} åŠ è½½å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”¬ Transformeræ”¹è¿›æ¶æ„æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    original_model, improved_model, hybrid_model = test_model_creation()
    
    if original_model and improved_model and hybrid_model:
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_forward_pass(original_model, improved_model, hybrid_model)
        
        # æµ‹è¯•ä¸åŒæ± åŒ–ç±»å‹
        test_different_pooling_types()
        
        # æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½
        test_config_loading()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("âœ… æ”¹è¿›çš„Transformeræ¶æ„å·²å‡†å¤‡å°±ç»ª")
        print("ğŸš€ å¯ä»¥å¼€å§‹å®éªŒå¯¹æ¯”äº†")
        
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç å®ç°")

if __name__ == "__main__":
    main()
