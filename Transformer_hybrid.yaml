data_path: ./Project1140.csv
save_dir: ./results/hybrid_transformer
future_hours: 24
train_ratio: 0.8
val_ratio: 0.1
plot_days: 7
start_date: '2022-01-01'
end_date: '2024-09-28'

train_params:
  batch_size: 64
  learning_rate: 0.0005
  loss_type: mse
  future_hours: 24

save_options:
  save_model: false
  save_predictions: true
  save_training_log: true
  save_excel_results: true

past_hours: 24
use_time_encoding: false
weather_category: ablation_11_features
use_pv: true
use_hist_weather: false
use_forecast: true
input_category: PV_plus_NWP

model: HybridTransformer  # 使用混合架构
model_complexity: low

model_params:
  low:
    d_model: 64
    num_heads: 4
    num_layers: 6
    hidden_dim: 64
    dropout: 0.1
    tcn_channels:
    - 64
    - 64
    - 32
    kernel_size: 3

epoch_params:
  low:
    epochs: 50

experiment_name: "Hybrid_Transformer"
description: "混合Encoder-Decoder架构的Transformer"
